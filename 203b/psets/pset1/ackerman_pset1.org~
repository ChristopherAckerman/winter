#+TITLE: Econ203B HW1
#+AUTHOR: Chris Ackerman\thanks{I worked on this problem set with Luna Shen.}
#+LATEX_HEADER: \usepackage{amsthm}
#+LATEX_HEADER: \usepackage{url}
#+LATEX_HEADER: \usepackage[margin=1.25in]{geometry}
#+LATEX_HEADER: \usepackage{hyperref} 
#+LATEX_HEADER: \usepackage[dvipsnames]{xcolor}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{enumitem}
#+LATEX_HEADER: \newtheorem*{definition}{Definition}
#+LATEX_HEADER: \newtheorem*{example}{Example}
#+LATEX_HEADER: \newtheorem*{theorem}{Theorem}
#+LATEX_HEADER: \newtheorem*{corollary}{Corollary}
#+LATEX_HEADER: \newtheorem*{exercise}{Exercise}
#+LATEX_HEADER: \newtheorem*{problem}{Problem}
#+LATEX_HEADER: \newtheorem{question}{Question}
#+LATEX_HEADER: \newcommand{\gr}{\textcolor{ForestGreen}}
#+LATEX_HEADER: \newcommand{\rd}{\textcolor{red}}
#+LATEX_HEADER: \newcommand{\R}{\mathbb{R}}
#+LATEX_HEADER: \newcommand{\p}{\mathbb{P}}
#+LATEX_HEADER: \newcommand{\E}{\mathbb{E}}
#+LATEX_HEADER: \newcommand{\inv}{^{-1}}
#+LATEX_HEADER: \newcommand{\frall}{\ \forall}
#+OPTIONS:  ':t

\newpage

* Question 1
 \begin{align*}
\intertext{In our sample, we have the minimization problem}
\beta_0 &= \arg \min_{b \in \R^2} \E [(Y - (1, X)b)^2]\\
\implies \beta_0 &= \E[(1, X)'(1, X)]\inv \E[Y, (1, X)'].\\
\intertext{Let's build the matrices we need to perform this calculation.}
\E \left[\begin{bmatrix}1\\ X \end{bmatrix}[1, X]\right] &= \begin{bmatrix}1 & \E[X] \\ \E[X] & \E[X^2]\end{bmatrix}\\
&= \begin{bmatrix}1 & \frac{1}{2} \\ \frac{1}{2} & \frac{1}{3}\end{bmatrix}\\
\intertext{The finite variance allows us to invert this matrix:}
E[(1, X)' (1, X)]\inv &= \begin{bmatrix}4 & -6\\ -6 & 12 \end{bmatrix}.\\
\intertext{Now, onto the next matrix. We're going to use the Law of Iterated Expectations for this one, since we know $\E[Y \mid X]$.}
\E[Y (1, X)'] &= \E \begin{bmatrix}\E[Y \mid X] \\ X \E [Y \mid X]\end{bmatrix}\\
&= \E \begin{bmatrix} X^2 \\ X^3 \end{bmatrix}\\
&= \begin{bmatrix}\frac{1}{3} \\ \frac{1}{4}\end{bmatrix}.\\
\intertext{We can plug these matrices into our FOC formula:}
\beta_0 &= \E[(1, X)'(1, X)]\inv \E[Y, (1, X)']\	\
&= \begin{bmatrix}4 & -6 \\ -6 & 12 \end{bmatrix}\begin{bmatrix}\frac{1}{3}\\ \frac{1}{4}\end{bmatrix}\\ &=\begin{bmatrix}- \frac{1}{6} \\ 1\end{bmatrix}
\end{align*}

\newpage
* Question 2
  \begin{align*}
\nabla \E [\E [Y \mid X] &= \left(\frac{\partial \E[Y \mid X]}{\partial X_1} \ldots \frac{\partial \E [Y \mid X]}{\partial X_d}\right)'\\
\E [\|\nabla \E[Y \mid X] - b\|^2]&= \E \left[\sum^d_{i = 1}\left(\frac{\partial \E [Y \mid X]}{\partial X_i} - b_i\right)^2\right]\\
\frac{\partial}{\partial b_i} \E[\| \nabla \E[Y \mid X] - b\|^2] &= -2 \left[\frac{\partial \E[Y\mid X]}{\partial x_i} - b_i\right]\\
&= 0\\
\implies b^* &= \E\left[\frac{\partial \E [Y \mid X]}{\partial X_i}\right]
\intertext{This expression is the same as}
b_0 &= \nabla \E [\E [Y \mid X]].
  \end{align*}
  \rd{TODO: Add counter example.}

  \newpage
* Question 3
  \begin{enumerate}[label=\alph*)]
\item 
\begin{align*}
\E[Y_i \mid D_i] &= \E[D_i Y_i(1) + (1 - D_i)Y_i(0) \mid D_i]\\
&= D_i \E [Y_i \mid D_i = 1] + (1 - D_i) \E [Y_i(0) \mid D_i = 0]\\
&= \E[Y_i \mid D_i = 0] + D_i (\E [Y_i \mid D_i = 1] - \E[Y_i (0) \mid D_i = 0])\\
&= \alpha_0 + D_i \beta_0     \\
\intertext{Now define}
\eta &= Y_i - \alpha_0 - D_i \beta_0 \\
&= Y_i - \E[Y_i \mid D_i]\\
\E[\eta \mid D_i] &= \E[Y_i - \alpha_0 - D_i \beta_0]\\
&= \E [Y_i \mid D_i] - \alpha_0 - D_i \beta_0\\
&= \alpha_o + D_i \beta_0 - \alpha_0 - D_i \beta_0\\
&= 0
\end{align*}
\item
\begin{align*}
\beta_0 &= \E [Y_i(1) \mid D_i = 1] - \E [Y_i(0) \mid D_i = 0]\\
&= \E[Y_i(1) \mid D_i = 1] - \E[Y_i(0) \mid D_i = 0] + \E[Y_i(0)\mid D_i = 0] - \E[Y_i(0)\mid D_i = 0]\\
&= \E[Y_i - Y_i(0) \mid D_i = 1] + \E[Y_i(0) \mid D_i = 1] - \E[Y_i (0) \mid D_i = 0]
\end{align*}
\item ATEU should be positive if college has a positive impact on earnings.

\item Selection bias should be positive. Regardless of whetehr they attended college, more talented individuals would have earned more, so we are conflating the effect of attending college with these individuals' innate abilities.

\item OLS is not consistent for ATE regardless of heterogeneity, because we will still have a bias term. Note that, even with heterogeneity, we are only trying to identify the \emph{average} treatment effect.
  \end{enumerate}

* Question 6
  For this problem, it's easier to work with the demeaned data, 
\[
\tilde{\beta}_n = \arg \min_{b \in \R^d} \frac{1}{n} \sum^n_{i = 1} ((Y_i - \overline{Y}_n) - (X_i - \overline{X}_n)' b)^2.
\]
\begin{align*}
\intertext{Starting with the forward direction,}
R^2 = 1 & \implies RSS = 0\\
\equiv 0 &= \sum^n_{i = 1} ((Y_i - \overline{Y}_n) - (X_i - \overline{X}_n)' \tilde{\beta}_n)^2\\
0 &= Y_i - \overline{Y}_n - (X_i - \overline{X}_n)' \tilde{\beta_n}\ \forall i\\
Y_i &= \underbrace{\overline{Y}_n - \overline{X}_n ' \tilde{\beta}_n}_{\alpha_0} + X_i' \underbrace{\tilde{\beta}_n}{b_0} \forall i\\
\intertext{To go the other way, suppose}
Y_i = a_0 + X_i' b_0 \ \forall i\\
\tilde{\beta}_n &= \arg \min_{b \in \R^d} \frac{1}{n} \sum^n_{i = 1} ((Y_i - \overline{Y}_n) - (X_i - \overline{X}_n)' b)^2\\
&= \arg \min_{b \in \R^d} \frac{1}{n} \sum^n_{i = 1} ((X_i - \overline{X}_n)' b_0 - (X_i - \overline{X}_n)' b)^2.\\
\intertext{The $\arg \min$ for this expression is $b = b_0$.}
Y_i - \overline{Y}_n &= a_0 - a_0 + (X_i - \overline{X}_n)' b_0\\
&= (X_i - \overline{X_n})' b_0\\
&= (X_i - \overline{X_n})' \tilde{\beta}_n\\
\implies RSS &= \sum^n_{i = 1} ((Y_i - \overline{Y}_n) - (X_i - \overline{X}_n)' \tilde{\beta}_n)^2 = 0\\
\implies R^2 &= 1
\end{align*}
* Question 8
  \begin{enumerate}[label=\alph*)]
\item See the python code below; the function that does this part of the problem is \tt{drop\_missing\_observations}.
\item The function that performs these calculations is \tt{calculate\_summary\_statistics}. \input{summary\_statistics.txt}
  \end{enumerate}
